{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be92d45c-9125-497e-9aa4-048ec0d82e54",
   "metadata": {},
   "source": [
    "# The Machine Learning Workflow Annotated\n",
    "\n",
    "Source: [Pytorch / Learn the Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a2e4b-0f67-433f-a8e0-787bd05d0c84",
   "metadata": {},
   "source": [
    "```{attention} TODO\n",
    "\n",
    "- Store a properly parametrized model in the repo and USE it (inference) before creating your own.\n",
    "- Simplify model archi, get rid of sequential\n",
    "- Explain logit stuff & give math formulas\n",
    "- Explain & test cross-entropy\n",
    "- Show that the neural network accepts batched data\n",
    "- Implement the \"PIL image to category -> proba sorted mapping\" as task.\n",
    "- Plot ReLU graph\n",
    "- Clean up the use of logits; here it actually refers to log-probabilites\n",
    "- Annotate & tweak learning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d361c-5e1b-46c5-b607-fd25566a8428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681cd9d-c913-440a-92b1-731956c5313b",
   "metadata": {},
   "source": [
    "## The FashionMNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d4548-fd7b-45c3-9a39-61e34a0e3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c617ba-f065-4430-807c-128e42c3a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.FashionMNIST(root=\"data\") # by default: training data set, no input/output transform, no download\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af20871-ef0d-4ac8-8524-036f5866bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is list-like ; each item in an input-output pair\n",
    "datum = data[0]\n",
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbe9ef-04ed-4d4e-b169-4f22f72853a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, index = datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e7b4c-3398-4518-8455-f8f9ab3cb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabdbce-3d62-4ad8-a784-474a2521073f",
   "metadata": {
    "user_expressions": [
     {
      "expression": "data.classes",
      "result": {
       "data": {
        "text/plain": "['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "outputs": [],
   "source": [
    "# The output is a number that denotes the class of the pictured object. The list of categories is:\n",
    "print(data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c1ec3-7059-4203-b699-d17de1e0b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the category name from the index:\n",
    "data.classes[index] # that checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8399b61-8763-4851-9273-fc82e89aa09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = [{\"image\": image, \"category\": data.classes[index]} for image, index in data]\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a39240-12b5-4062-ae4e-a860d1bc09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "\n",
    "def image_formatter(image):\n",
    "    with io.BytesIO() as buffer:\n",
    "        image.save(buffer, \"jpeg\")\n",
    "        _bytes = buffer.getvalue()\n",
    "    _base64 = base64.b64encode(_bytes).decode(\"ascii\")\n",
    "    return f'<img src=\"data:image/jpeg;base64, {_base64}\">'\n",
    "\n",
    "HTML(df.head().to_html(formatters={'image': image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754275e-191b-4517-b4a7-df009dc475ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch only want to deal with numeric array called \"tensors\", not images.\n",
    "# So, it is perfectly happy with the output as a numeric value, but we need to transform the input\n",
    "image_to_tensor = torchvision.transforms.ToTensor()\n",
    "t = image_to_tensor(image)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199069a5-2fe5-4ee9-bc6a-40332db52cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape, t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc73a5-dd37-45b9-89ab-34e3f10506e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No information has been lost in the conversion process!\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(t.squeeze(), cmap=\"grey\")\n",
    "plt.colorbar()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ce320-c734-4ab8-a377-c4b9c235c54a",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd85254-4940-4b62-8fee-56f4480ba11f",
   "metadata": {},
   "source": [
    "The model architecture is going to assign to each image input the vector of probability $p_i$ that the item belongs to the $i$th class.\n",
    "The class prediction is simply the class with the highest probability, but the fact that all $p_i$ are know allows us to evaluate the trust that we should have in the prediction.\n",
    "\n",
    "The nitty-gritty details:\n",
    "\n",
    "  - The image should be given as a 28x28 tensor (instead of say a PIL image),\n",
    "\n",
    "  - The model does actually not output the probabilities $p_i \\in [0, 1]$ directly but the corresponding unnormalized log probabilities\n",
    "    $$\n",
    "    \\ell_i := \\log p_i + c\n",
    "    $$\n",
    "    Compute $p_i$ with:\n",
    "    $$\n",
    "    p_i = \\frac{\\exp \\ell_i}{\\sum_{j=0}^{9} \\exp \\ell_j}.\n",
    "    $$\n",
    "\n",
    "    The pytorch [`softmax`](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) function implements this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ed589-c9b9-4376-8ff5-ded427307b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear_1 = torch.nn.Linear(28*28, 512)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(512, 512)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.linear_3 = torch.nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, image_tensor):\n",
    "        image_flat = self.flatten(image_tensor)\n",
    "        x_0 = image_flat\n",
    "        x_1 = self.linear_1(x_0)\n",
    "        x_1 = self.relu_1(x_1)\n",
    "        x_2 = self.linear_2(x_1)\n",
    "        x_2 = self.relu_2(x_2)\n",
    "        x_3 = self.linear_3(x_2)\n",
    "        logits = x_3\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d4e2f-41a4-4ee7-8d36-a5cb59275934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b400bc3-b2c2-4dd2-96cc-0d0a157ee420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the (trained) model state for this architecture\n",
    "model.load_state_dict(torch.load(\"models/base-model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0051c-f13d-41f9-a835-9fd2bcf92722",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor, cls = training_data[0]\n",
    "plt.imshow(image_tensor.squeeze(), cmap=\"grey\")\n",
    "plt.grid(False)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14044f-fbe2-4375-8890-66d9d8099e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(image_tensor)\n",
    "logits = logits.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d92d7a-14dc-4b32-bd97-3e0a35e6fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = torch.nn.functional.softmax(logits, dim=-1)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e172fc-3bec-4385-86af-3d405d795484",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_dict = {training_data.classes[i]: p.item() for i, p in enumerate(probas)}\n",
    "probas_dict = dict(sorted(list(probas_dict.items()), key=lambda pair: -pair[1]))\n",
    "probas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92df69a-2a54-492d-9aee-dc31ec768d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set_theme()\n",
    "sns.barplot(probas_dict)\n",
    "plt.gcf().set_figwidth(12)\n",
    "plt.gca().set_ylabel(\"Probability\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4f282-7864-4344-ab7b-0e9a6046e41b",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4e731-a71b-4956-aecd-83ba9e2a2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(f\"type: {type(p.data).__name__}, shape: {tuple(p.shape)!s:<10}, data type: {p.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476ad61-4fe6-4ea0-913e-ec9edde2f0be",
   "metadata": {},
   "source": [
    "```{tip} Model Size\n",
    "How many scalar parameters describe the model? What is the corresponding model size in MB?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7577531-3619-44b2-8447-2b7b57f1b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    num_params += torch.prod(torch.tensor(p.shape)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad32eff-2569-4977-b77f-5e60c3f60a09",
   "metadata": {
    "user_expressions": [
     {
      "expression": "num_params",
      "result": {
       "data": {
        "text/plain": "669706"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "num_params // 1_000",
      "result": {
       "data": {
        "text/plain": "669"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "round(num_params * 4 / 1_000_000, 1)",
      "result": {
       "data": {
        "text/plain": "2.7"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "There are {eval}`num_params` ($\\approx$ {eval}`num_params // 1_000`K) parameters in the model. The size of each parameter is 4B, hence the total size is {eval}`round(num_params * 4 / 1_000_000, 1)`MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a764e4-ead4-469e-8f4f-ea3824bbfe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    to_tensor = torchvision.transforms.ToTensor()\n",
    "    input = to_tensor(image)\n",
    "    output = model(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ed00e-a735-4af5-86b6-ab01c35d7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output.data\n",
    "probas = torch.nn.functional.softmax(logits, dim=-1)\n",
    "probas = probas.squeeze()\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9890cb8-a0ba-4859-a3c9-86dc21652f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set_theme()\n",
    "probas_dict = {training_data.classes[i]: p.item() for i, p in enumerate(probas)}\n",
    "probas_dict = dict(sorted(list(probas_dict.items()), key=lambda pair: -pair[1]))\n",
    "sns.barplot(probas_dict)\n",
    "plt.gcf().set_figwidth(12)\n",
    "plt.gca().set_ylabel(\"Probability\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa49f3-2493-465f-8757-94a4af0f188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in probas_dict:\n",
    "    most_likely_category = key\n",
    "    break\n",
    "most_likely_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fd95f-2ab6-4bb5-a7ca-7caa1e8f078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(image):\n",
    "    to_tensor = torchvision.transforms.ToTensor()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = to_tensor(image)\n",
    "        output = model(input)\n",
    "    logits = output.data.squeeze()\n",
    "    probas = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    category_proba = [(training_data.classes[i], p.item()) for i, p in enumerate(probas)]\n",
    "    category_proba = sorted(category_proba, key=lambda pair: -pair[1])\n",
    "    return dict(category_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b44433c-5d26-407a-a64b-883c06ee6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3482e-affa-4b2e-a34b-264a73b3b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(prediction(image))\n",
    "plt.gcf().set_figwidth(12)\n",
    "plt.gca().set_ylabel(\"Probability\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e5757-0ecf-4e55-8cc5-3c177928ea41",
   "metadata": {},
   "source": [
    "### Under the Hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a01b45-d85b-4789-bc3d-c72b49c5950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a39cf1-aa35-45b8-ad37-15db36f4de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdafdc-c5d2-4e4f-9bfe-7162bb04e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torchvision.transforms.ToTensor()(image)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5bc9d-a6a8-4b3b-b7a9-c5f3e7b790c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.flatten(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee934035-f1e7-48f9-a739-9afb00f7f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00595861-b73c-4fa4-be4b-8f064a41847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear_1.in_features == 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979cd1d-6e33-46b8-b377-a31d9985c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_1_params = {name: param.data for name, param in model.linear_1.named_parameters()}\n",
    "linear_1_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77d92a-bba8-4333-8e1b-45077702a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = linear_1_params[\"bias\"]\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef506f6e-9bb6-4d46-b392-96657feec93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = linear_1_params[\"weight\"]\n",
    "A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e03e0a-2832-4e12-9cf8-2aa92a52dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = torchvision.transforms.ToTensor() \n",
    "t = to_tensor(image)\n",
    "print(t.shape)\n",
    "tf = torch.flatten(t)\n",
    "print(tf.shape)\n",
    "x1 = A1 @ tf + b1\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb057b-6815-46c0-928b-4bcdd9771fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = model.relu_1(x1)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e5c46-52a8-4fe5-a451-999dfe396a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.relu_1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1c3ad-6fe8-423d-8c18-16d97188cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_2_params = {name: param.data for name, param in model.linear_2.named_parameters()}\n",
    "A2 = linear_2_params[\"weight\"]\n",
    "b2 = linear_2_params[\"bias\"]\n",
    "x2 = A2 @ x1 + b2\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afeee39-f92c-430e-8fab-75f9da4ab7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = model.relu_2(x2)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359b5a0-670c-49fc-99d7-79cdb586d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_3_params = {name: param.data for name, param in model.linear_3.named_parameters()}\n",
    "A3 = linear_3_params[\"weight\"]\n",
    "b3 = linear_3_params[\"bias\"]\n",
    "x3 = A3 @ x2 + b3\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574bed7-4755-4847-9268-ec1bccdff204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.nn.functional.softmax(x, dim=0)\n",
    "\n",
    "probas = softmax(x3)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711f687-e2c7-4349-9155-c17d559898f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {training_data.classes[i]: p.item() for i, p in enumerate(probas)}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48934c97-27f8-4d11-a2d1-af19e0cc5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set_theme()\n",
    "sns.barplot(data)\n",
    "plt.gcf().set_figwidth(12)\n",
    "plt.gca().set_ylabel(\"Probability\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b94a0-b39a-4637-b5de-3090438183d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(t).data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979dd2d-f699-4074-9c81-5c6988b8332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = torch.nn.functional.softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb45c1-34cd-4e47-be96-18b58d90eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {training_data.classes[i]: p.item() for i, p in enumerate(ps)}\n",
    "sns.barplot(data)\n",
    "plt.gcf().set_figwidth(16)\n",
    "plt.gca().set_ylabel(\"Probability\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f1b95-6b16-4504-85e9-53521e1c1737",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b12003-c8b8-4aa1-8636-2fd71eba47ee",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fbc792-5d57-4dac-82b5-4e2720faa1d7",
   "metadata": {},
   "source": [
    "The loss function is a measure of the model prediction error: the mismatch between the output predicted by the model and the \"real\" output. Here, in the context of category identification, we use the cross-entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc958b3-06de-42d3-b474-d050064e2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829fa6f-7bd3-4543-af3d-ff1787adc15f",
   "metadata": {},
   "source": [
    "It measures the differences between two probability distributions: here a computed probability distribution $p=(p_0, \\dots, p_{n-1})$ and a \"deterministic\" distribution $q=e_i$ with\n",
    "$$\n",
    "e_i=(0, \\dots, 0, 1, 0, \\dots, 0) \\;\\;\\; \\mbox{($1$ in position $i$)}\n",
    "$$\n",
    "with:\n",
    "$$\n",
    "\\mathrm{loss}(p, e_i) = - \\log p_i. \n",
    "$$\n",
    "The loss is zero when $p_i = 1$ (perfect match) and $-\\infty$ when $p_i = 0$. It does not depend on the distribution of the $p_j$ for $j \\neq i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594209a-b512-4e6e-93f9-2b71ff10523d",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "The pytorch cross entropy function works directly with unnormalized log probabilities \n",
    "$$\n",
    "\\ell_i := \\log p_i + c\n",
    "$$\n",
    "(the log probabilities up to a shared constant $c$) instead of the probabilites $p$. \n",
    "The deterministic distribution is also specified by the index $i$ instead of the vector $q=e_i$.\n",
    "Hence, it actually computes\n",
    "$$\n",
    "\\mathrm{loss}(\\ell, i) := -\\ell_i  + \\log \\left( \\sum_je^{\\ell_j} \\right). \n",
    "$$\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4e5b5-ed42-40b7-87d1-3bac24922523",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e0aa6-5996-434c-9dd8-39efe834f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(\n",
    "    input=torch.tensor([1.0, 0.0]).log(), \n",
    "    target=torch.tensor(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180327b1-3359-4f73-8732-00a88ed1d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(\n",
    "    input=torch.tensor([0.0, 1.0]).log(), \n",
    "    target=torch.tensor(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7166f6d-2ab0-43d9-8a6f-d3a63360cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(\n",
    "    input=torch.tensor([0.5, 0.5]).log(), \n",
    "    target=torch.tensor(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015f27e-cf7f-49d6-a87b-5450eb3767ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "- torch.tensor(0.5).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1b949-21a5-4bdf-a87a-b1d31017a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(\n",
    "    input=torch.tensor([2/3, 1/3]).log(), \n",
    "    target=torch.tensor(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c2bec-2ffa-4e33-83bc-70e4ecf7e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(\n",
    "    input=torch.tensor([200.0, 100.0]).log(), \n",
    "    target=torch.tensor(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76498a78-0ccb-415e-a7e2-130e4040d35e",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9ba81-fcc2-488b-b697-2f7ae3ad1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"X = [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402984b7-449a-4418-8587-d40495519216",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c6413-f34f-4060-a4ab-71fc1dd26137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05342f5e-b04b-4698-b192-a13d9015e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - score, the probability of a correct inference on the test dataset\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.2f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e912bc-4e8a-4dbb-824f-d62ae9f2ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "model.train()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "score = 0.0\n",
    "new_score = test(test_dataloader, model, loss_function)\n",
    "epoch = 0\n",
    "keep_learning = True\n",
    "while keep_learning:\n",
    "    epoch += 1\n",
    "    score = new_score\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_function, optimizer)\n",
    "    new_score = test(test_dataloader, model, loss_function)\n",
    "    keep_learning = new_score > score\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ce9ce-c190-4653-8c52-2ae96989779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25d704-be52-414f-a3c5-b6273237ad14",
   "metadata": {},
   "source": [
    "## Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb319a0-3703-44a9-bbbb-8503012ffe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"models/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87081abf-1fb9-4ac6-9067-7490581dbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_data.classes\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22c8ef-7eb5-4639-ad72-0c72e5616673",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "input, output = test_data[0][0], test_data[0][1]\n",
    "print(f\"Known category: {test_data.classes[output]}\")\n",
    "logits = model(input)\n",
    "logits = logits.data.squeeze()\n",
    "probas = torch.nn.functional.softmax(logits, dim=-1)\n",
    "print(f\"Predicted category: {test_data.classes[probas.argmax().item()]}\")\n",
    "data = {training_data.classes[i]: p.item() for i, p in enumerate(probas)}\n",
    "sns.barplot(data)\n",
    "plt.gcf().set_figwidth(16)\n",
    "plt.gca().set_ylabel(\"Probability\")\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
